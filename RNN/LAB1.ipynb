{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "train = pd.read_csv('./dataset/train_SectionDataset.csv')\n",
    "test = pd.read_csv('./dataset/test_SectionDataset.csv')\n",
    "\n",
    "train_text = np.array(train)\n",
    "x_train = [] #학습셋 제목\n",
    "y_train = [] #학습셋 라벨\n",
    "for i in range(len(train_text)):\n",
    "    x_train.append(train_text[i][0])\n",
    "    y_train.append(train_text[i][1])\n",
    "\n",
    "test_text = np.array(test)\n",
    "x_test = [] #테스트셋 제목\n",
    "y_test = [] #테스트셋 라벨\n",
    "for i in range(len(test_text)):\n",
    "    x_test.append(test_text[i][0])\n",
    "    y_test.append(test_text[i][1])\n",
    "\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(x_train + x_test)\n",
    "\n",
    "token.fit_on_texts(x_test)\n",
    "token.fit_on_texts(x_train)\n",
    "\n",
    "x_token = token.texts_to_sequences(x_train + x_test) #토큰화\n",
    "word_size = len(token.word_index)\n",
    "\n",
    "train_token = token.texts_to_sequences(x_train)\n",
    "test_token = token.texts_to_sequences(x_test)\n",
    "\n",
    "#원핫인코딩\n",
    "y = y_train + y_test\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "padded_x_train = pad_sequences(train_token, 18)\n",
    "padded_x_test = pad_sequences(test_token, 18)\n",
    "padded_x = pad_sequences(x_token, 18)\n",
    "\n",
    "# 모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size + 1, 100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(64, 5, padding='valid', activation='relu',strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(55))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# 모델의 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y = np.array(y)\n",
    "model.fit(padded_x, y, batch_size=10, epochs=20)\n",
    "\n",
    "# 테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(padded_x_test, y_test)[1]))\n",
    "\n",
    "print(\"첫번째 학습셋 입력: \" , x_train[0])\n",
    "print(\"첫번째 테스트셋 입력: \" , x_test[0])\n",
    "print(\"첫번째 학습셋 결과 one-hot 출력: \", y_train_encoded[0])\n",
    "print(\"첫번째 테스트셋 결과 one-hot 출력: \", y_test_encoded[0])\n",
    "print(\"전체 데이터셋 단어 토큰 개수: \", word_size)\n",
    "print(\"첫번째 학습셋 토큰 결과: \", train_token[0])\n",
    "print(\"첫번째 테스트셋 토큰 결과: \", test_token[0])\n",
    "trainMax = max(len(i) for i in train_token)\n",
    "print(\"학습셋 제목 최대 길이: \", trainMax)\n",
    "testMax = max(len(i) for i in test_token)\n",
    "print(\"테스트셋 제목 최대 길이: \", testMax)\n",
    "print(\"첫번째 학습셋 패딩 토큰: \", padded_x_train[0])\n",
    "print(\"첫번째 테스트셋 패딩 토큰: \", padded_x_test[0])\n",
    "\n",
    "import pickle\n",
    "with open('test_token.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_token, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ]
}