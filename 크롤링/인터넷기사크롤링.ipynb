{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#정치\n",
    "url_0 = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=100\" \n",
    "#url = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101#&date= 00:00:00&page=2\" \n",
    "\n",
    "#경제\n",
    "url_1 = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101\" \n",
    "\n",
    "#사회\n",
    "url_2 = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=102\"\n",
    "\n",
    "#IT/과학\n",
    "url_3 = \"https://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=105\" \n",
    "\n",
    "#크롤링 자동 방지 해제 \n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"}\n",
    "result_0 = requests.get(url_0, headers=headers)\n",
    "result_1 = requests.get(url_1, headers=headers)\n",
    "result_2 = requests.get(url_2, headers=headers)\n",
    "result_3 = requests.get(url_3, headers=headers)\n",
    "#print(result)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup_0 = BeautifulSoup(result_0.text, 'html.parser')\n",
    "soup_1 = BeautifulSoup(result_1.text, 'html.parser')\n",
    "soup_2 = BeautifulSoup(result_2.text, 'html.parser')\n",
    "soup_3 = BeautifulSoup(result_3.text, 'html.parser')\n",
    "#print(soup)\n",
    "\n",
    "news_titles_0 = soup_0.find_all(class_='cluster_text_headline')\n",
    "news_titles_1 = soup_1.find_all(class_='cluster_text_headline')\n",
    "news_titles_2 = soup_2.find_all(class_='cluster_text_headline')\n",
    "news_titles_3 = soup_3.find_all(class_='cluster_text_headline')\n",
    "#news_titles = soup.select('.cluster_text_headline')\n",
    "#print(news_titles)\n",
    "\n",
    "print('총 뉴스 제목 개수: ', len(news_titles_0))\n",
    "for item in news_titles_0:\n",
    "    print(item.get_text())\n",
    "    #print(item['href'])\n",
    "\n",
    "#불필요한 글자 제거\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.path.isfile('./test_SectionDataset.csv'):\n",
    "    df = pd.read_csv('./test_SectionDataset.csv', names=['title', 'section'], header=0)\n",
    "else:\n",
    "    bodyStruc = {'title': [], 'section': []}\n",
    "    df = pd.DataFrame( bodyStruc, columns=['title', 'section'] )\n",
    "    \n",
    "for item in news_titles_0:\n",
    "    texts = item.get_text()\n",
    "    texts = texts.replace(',', \"\")\n",
    "    texts = texts.replace('\\'', \"\")\n",
    "    texts = texts.replace('\\\"', \"\")\n",
    "    texts = texts.replace('…', \" \")\n",
    "    print(texts)\n",
    "    oneData = {'title': texts, 'section': '0'}\n",
    "    df = df.append( oneData, ignore_index=True )\n",
    "\n",
    "for item in news_titles_1:\n",
    "    texts = item.get_text()\n",
    "    texts = texts.replace(',', \"\")\n",
    "    texts = texts.replace('\\'', \"\")\n",
    "    texts = texts.replace('\\\"', \"\")\n",
    "    texts = texts.replace('…', \" \")\n",
    "    print(texts)\n",
    "    oneData = {'title': texts, 'section': '1'}\n",
    "    df = df.append( oneData, ignore_index=True )\n",
    "    \n",
    "for item in news_titles_2:\n",
    "    texts = item.get_text()\n",
    "    texts = texts.replace(',', \"\")\n",
    "    texts = texts.replace('\\'', \"\")\n",
    "    texts = texts.replace('\\\"', \"\")\n",
    "    texts = texts.replace('…', \" \")\n",
    "    print(texts)\n",
    "    oneData = {'title': texts, 'section': '2'}\n",
    "    df = df.append( oneData, ignore_index=True )\n",
    "    \n",
    "for item in news_titles_3:\n",
    "    texts = item.get_text()\n",
    "    texts = texts.replace(',', \"\")\n",
    "    texts = texts.replace('\\'', \"\")\n",
    "    texts = texts.replace('\\\"', \"\")\n",
    "    texts = texts.replace('…', \" \")\n",
    "    print(texts)\n",
    "    oneData = {'title': texts, 'section': '3'}\n",
    "    df = df.append( oneData, ignore_index=True )\n",
    "    \n",
    "df.to_csv('./test_SectionDataset.csv', encoding='UTF-8', index=False, header=True)"
   ]
  }
 ]
}